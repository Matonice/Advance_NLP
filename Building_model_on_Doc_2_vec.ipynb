{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqjw+YI5I4CUatx04eKV2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matonice/Advance_NLP/blob/main/Building_model_on_Doc_2_vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U04peQFGwV2Z"
      },
      "outputs": [],
      "source": [
        "#Read in data, clean it, and then split it into train and test split\n",
        "import gensim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.set_option(\"display.max_colwidth\", 100)\n",
        "\n",
        "messages = pd.read_csv('SMSSpamCollection.tsv', sep='\\t', header=None)\n",
        "#messages = messages.drop(labels = [\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
        "messages.columns = [\"label\", \"text\"]\n",
        "messages[\"text_clean\"] = messages[\"text\"].apply(lambda x: gensim.utils.simple_preprocess(x))\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(messages[\"text_clean\"], messages[\"label\"], test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create  tagged document objects to prepare to train the model\n",
        "tagged_docs_train = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(x_train)]\n",
        "tagged_docs_test = [gensim.models.doc2vec.TaggedDocument(v, [i]) for i, v in enumerate(x_test)]"
      ],
      "metadata": {
        "id": "-M5wap0hwob4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What do these TaggedDocument objects look like?\n",
        "tagged_docs_train[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqFmUyrexwBh",
        "outputId": "c299f969-07a8-407f-82fc-2760dda600bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TaggedDocument(words=['long', 'after', 'quit', 'get', 'on', 'only', 'like', 'minutes', 'day', 'as', 'it', 'is'], tags=[0]),\n",
              " TaggedDocument(words=['the', 'monthly', 'amount', 'is', 'not', 'that', 'terrible', 'and', 'you', 'will', 'not', 'pay', 'anything', 'till', 'months', 'after', 'finishing', 'school'], tags=[1]),\n",
              " TaggedDocument(words=['miss', 'you', 'so', 'much', 'so', 'desparate', 'have', 'recorded', 'the', 'message', 'you', 'left', 'for', 'me', 'the', 'other', 'day', 'and', 'listen', 'to', 'it', 'just', 'to', 'hear', 'the', 'sound', 'of', 'your', 'voice', 'love', 'you'], tags=[2]),\n",
              " TaggedDocument(words=['congrats', 'year', 'special', 'cinema', 'pass', 'for', 'is', 'yours', 'call', 'now', 'suprman', 'matrix', 'starwars', 'etc', 'all', 'free', 'bx', 'ip', 'we', 'pm', 'dont', 'miss', 'out'], tags=[3]),\n",
              " TaggedDocument(words=['idc', 'get', 'over', 'here', 'you', 'are', 'not', 'weaseling', 'your', 'way', 'out', 'of', 'this', 'shit', 'twice', 'in', 'row'], tags=[4]),\n",
              " TaggedDocument(words=['actually', 'deleted', 'my', 'old', 'website', 'now', 'blogging', 'at', 'magicalsongs', 'blogspot', 'com'], tags=[5]),\n",
              " TaggedDocument(words=['hey', 'what', 'are', 'you', 'doing', 'no', 'reply', 'pa'], tags=[6]),\n",
              " TaggedDocument(words=['dear', 'dave', 'this', 'is', 'your', 'final', 'notice', 'to', 'collect', 'your', 'tenerife', 'holiday', 'or', 'cash', 'award', 'call', 'from', 'landline', 'tcs', 'sae', 'box', 'cw', 'wx', 'ppm'], tags=[7]),\n",
              " TaggedDocument(words=['don', 'look', 'back', 'at', 'the', 'building', 'because', 'you', 'have', 'no', 'coat', 'and', 'don', 'want', 'you', 'to', 'get', 'more', 'sick', 'just', 'hurry', 'home', 'and', 'wear', 'coat', 'to', 'the', 'gym'], tags=[8]),\n",
              " TaggedDocument(words=['please', 'call', 'our', 'customer', 'service', 'representative', 'on', 'between', 'am', 'pm', 'as', 'you', 'have', 'won', 'guaranteed', 'cash', 'or', 'prize'], tags=[9])]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a basic doc2vec model\n",
        "d2v_model = gensim.models.Doc2Vec(tagged_docs_train,\n",
        "                                  vector_size=100,\n",
        "                                  window=5,\n",
        "                                  min_count=2)"
      ],
      "metadata": {
        "id": "gngJU25syRN0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer the vectors to be used in training and testing\n",
        "train_vectors = [d2v_model.infer_vector(v.words) for v in tagged_docs_train]\n",
        "test_vectors = [d2v_model.infer_vector(v.words) for v in tagged_docs_test]"
      ],
      "metadata": {
        "id": "lCC52fCxzROB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit RandomForestClassifier ON Top Of Document Vectors"
      ],
      "metadata": {
        "id": "nV-WZ0wx0-rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit a basic Random Forest model on top of the vectors\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_model = rf.fit(train_vectors, y_train.values.ravel())\n",
        "\n",
        "y_pred = rf_model.predict(test_vectors)\n",
        "\n",
        "precision = precision_score(y_test, y_pred, pos_label=\"spam\")\n",
        "recall = recall_score(y_test, y_pred, pos_label=\"spam\")\n",
        "print(\"precision: {} / Recall: {} / Accuracy: {}\".format(\n",
        "    round(precision, 3), round(recall, 3), round((y_pred==y_test).sum()/len(y_pred), 3)\n",
        "))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k_Y75RPzbFN",
        "outputId": "32e76085-c7f6-46e3-cc83-6145ea1ddf6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.9 / Recall: 0.061 / Accuracy: 0.874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uWOc3dn224js"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}